---
title: "Data Best Practices"
author: "<b>USGS</b>: Alison P Appling"
date: "`r format(Sys.time(), '%d %B, %Y')`"
knit: (function(inputFile, encoding) { 
      out_dir <- 'test';
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file='../best_practices.html') })
output: 
  ioslides_presentation: 
    css: ../styles.css
    logo: ../images/simple-shadow.png
    smaller: yes
    transition: faster
---

```{r directive, include=FALSE}
# acquisition and management of large datasets as well as quality control. Your
# expertise in these topics is really beneficial to the group since we will be
# dedicating a considerable amount of time finding/curating datasets.  Would you
# be willing to share some techniques/best practices with the group during part
# of the webinar on Thursday 3/10? The idea is to provide some exposure to
# helpful approaches to data management as we move forward refining group
# research questions.

# Reproducible workflows
# Reproducible data access
# Reproducible modeling
```

## Upping your Analytical Game

### Efficiency

> - quickly write, revise, run, and revisit your code

### Transparency

> - let others see & understand what you're doing

### Reproducibility

> - enable anyone to run your analyses

```{r, include=FALSE}
# Reproducibility is the most stringent of of E,T,R, so we'll use that word to indicate all three
# Anything you do to implement one probably helps with the others
```

## Benefits

- implement each idea just once
- change data or methods freely
- handle more data & complexity
- run on clusters/cloud
- share with others
- share with your future self

```{r, include=FALSE}
# future self: paper revisions, check an analysis step, reuse code in a new project
```

## Analyses are reproducible when they're:

### Readable
- readable code
- traceable data flow

### Self-contained
- complete from data to reports
- dependencies are included or public & documented

### Incorruptible
- judicious redundancy
- code versioning
- automated data flow

```{r, include=FALSE}
# the above is the talk outline

# Reproducible Research = integrate your data, text, code, and results. this is
# sometimes but not always what you want, especially with modeling
```

## Readable code: Principles

- comments on goals & rationale
- meaningful variable names
- meaningful white space
- clarity via conciseness
- decomposition
- don't repeat yourself

## Readable code: Examples

### Exhibit A

```{r, eval=FALSE}
for(i in seq_len(n)[-1]) {
mu[i,d]<-  X[i-1, d]+((GPP[d]/z)*(light[i,d]/(sum(light[,d]))))+ (ER[d]*0.006944/z)+
  (K[d]/(600/(1800.6-(temp[i,d]*120.1)+(3.7818*temp[i,d]^2)-(0.047608*temp[i,d]^3)))^
-0.5) * 0.0069444*(  ((exp(2.00907 + 3.22014 * (log((298.15-temp[i,d]) / (273.15 + 
temp[i,d]))) + 4.0501 * (log((298.15 - temp[i,d]) / (273.15 + temp[i,d]))) ^ 2 + 
4.94457 * (log((298.15 - temp[i,d]) / (273.15 + temp[i,d]))) ^ 3 - 0.256847 * 
  (log((298.15 - temp[i,d]) / (273.15 + temp[i,d]))) ^ 4 + 3.88767 * (log((298.15 - 
temp[i,d]) / (273.15 + temp[i,d]))) ^ 5)) * 1.4276 * bp / 760) *satcor-X[i-1,d] )}
```

### Exhibit B

```{r, eval=FALSE}
# Compute the O2-specific reaeration coefficient for each timestep
K <- convert_k600_to_kGAS(K600.daily, temperature=temp.water, gas="O2") * frac.D

# Dissolved oxygen (DO) at each time i is a function of DO at time i-1 plus
# productivity, respiration, and reaeration
for(i in seq_len(n)[-1]) {
  DO.mod[i] <- 
    DO.mod[i-1] +
    GPP[i] + 
    ER[i] + 
    K[i] * (DO.sat[i] - DO.mod[i-1])
}
```

## Traceable data flow: Principles

- directories should be as readable as code
- tell one convergent story

<p align="center">
  <img src="images/data_river.png" alt="dependencies" style="width: 700px;" align="center"/>
</p>


## Traceable data flow: Simple example

```{r, eval=FALSE}
    01_download.R
    01_downloaded_data.csv
    02_munge.R
    02_munged_data.Rds
    03_model.R
    03_model_output.Rds
    04_report.Rmd
    04_report_doc.docx
```

## Traceable data flow: Three-step example

```{r, eval=FALSE}
+---01_data
|       downloaded_data.csv
|       
+---02_cache
|       a_munged_data.Rds
|       b_model_output.Rds
|       
+---03_results
|       report_doc.docx
|       
\---code
        01_download.R
        02_munge.R
        03_model.R
        04_report.Rmd
```

## Traceable data flow: Many-step example

```{r, eval=FALSE}
+---01_data
|   +---code
|   |       download.R
|   \---out
|           downloaded_data.csv
+---02_munge
|   +---code
|   |       munge.R
|   +---doc
|   |       probable_outliers.png
|   +---in
|   |       outliers_to_remove.txt
|   \---out
|           munged_data.Rds
+---03_model
|   +---code
|   |       model.R
|   +---in
|   |       model_config.txt
|   \---out
|           model_output.Rds
+---04_report
|   +---code
|   |       report.Rmd
|   \---out
|           report_doc.docx
\---lib
```

## Traceable data flow: Principles

- directories should be as readable as code
- tell one convergent story
- **expect tangents**

<p align="center">
  <img src="images/data_river_eddy.png" alt="dependencies" style="width: 700px;" align="center"/>
</p>

## Traceable data flow: Expect tangents

```{r, eval=FALSE}
+---01_data
|       downloaded_data.csv
|       
+---02_cache
|       a_munged_data.Rds
|       b_model_output.Rds
|       
+---03_results
|       report_doc.docx
|       
+---code
|       01_download.R
|       02_munge.R
|       03_model.R
|       04_report.Rmd
|       
\---ideas
    +---150911_lmer_model.R
    |      try_mixed_mod.R
    |
    \---160227_facet_plot.R
           plot_a.R
           plot_everything.R
```

## Traceable data flow: All about dependencies

<p align="center">
  <img src="images/dependencies.png" alt="dependencies" style="width: 700px;" align="center"/>
</p>


## Self-contained analyses: Also about dependencies

- complete dependency chain from data to reports
- dependencies are (1) public & documented or (2) embedded

<p align="center">
  <img src="images/dependencies.png" alt="dependencies" style="width: 500px;" align="center"/>
</p>

## Self-contained analyses: Data access

### Principles
- document your data's provenance
- script your data access
- cache a copy, but trust the source

<p align="center">
  <img src="images/dependencies_small.png" alt="dependencies" style="width: 400px;" align="right"/>
</p>

### Methods
- `download.file()` # http
- `httr::GET()` # https
- [`dataRetrieval`](https://github.com/USGS-R/dataRetrieval)
- [`geoknife`](https://github.com/USGS-R/geoknife)
- [`dataone`](https://github.com/DataONEorg/rdataone)

### Example

```{r, eval=FALSE}
# Download & unzip the UMESC fisheries data
url <- 'http://www.umesc.usgs.gov/data_library/fisheries/LTRM_FISH_DATA_ENTIRE.zip'
fishzipfile <- tempfile()
download.file(url, destfile=fishzipfile)
unzip(fishzipfile, exdir='data', junkpaths=TRUE)
```

## Self-contained analyses: Quality control

### Principles
- expect flaws, even from the best data sources
- preserve 'raw' data
- script your corrections
- document your reasons

<p align="center">
  <img src="images/dependencies_qc.png" alt="dependencies" style="width: 700px;" align="center"/>
</p>

## Self-contained analyses: Quality control

### Methods
- check your n's (`nrow()`, `length(unique())`)
- check for outliers (`sd()`, [`sensorQC::flag()`](https://github.com/USGS-R/sensorQC))
- check for duplicates & typos (`table()`)
- check the timezones (`lubridate::tz()`)
- visualize (`plot(x=lon, y=lat)`)

<p align="center">
  <img src="images/sensorqc.png" alt="sensorqc" style="width: 400px;" align="right"/>
</p>

## Self-contained analyses: Scalable modeling

### Remember decomposition
- separate the model, model manager, and configurations

### Value metadata
- model run metadata = goal + configuration + model version + summary
- choose artifacts that will last

### Value compute time & person time
- store everything until you can't
- pick formats that allow quick review (tables, text, and png)

## Incorruptible analyses: Judicious redundancy

<p align="center">
  <img src="http://www.phdcomics.com/comics/archive/phd101212s.gif" alt="final.doc" style="width: 400px;" align="center"/>
</p>

## Incorruptible analyses: Judicious redundancy

<p align="center">
  <img src="images/dependencies.png" alt="dependencies" style="width: 500px;" align="right"/>
</p>

- one copy of data
- one copy of results
- never rely on the cache
- do use the cache

## Incorruptible analyses: Code versioning

<p align="center">
  <img src="images/github_history.png" alt="dependencies" style="width: 350px;" align="right"/>
</p>

### Git & GitHub

- keep ALL the "final.doc"s
- option to revert

<p align="center">
  <img src="http://swcarpentry.github.io/git-novice/fig/play-changes.svg" alt="dependencies" style="width: 350px;" align="left"/>
</p>


## Incorruptible analyses: Code versioning

<p align="center">
  <img src="images/github_chatdiff.png" alt="dependencies" style="width: 450px;" align="right"/>
</p>

### Benefits

- collaborate on files
- prevent conflicting changes
- manage tasks
- give & get help
- conduct research openly


## Incorruptible analyses: Automated data flow

### Needs

- document the file dependency structure
- update files when their dependencies change
- only update files when they need it

<p align="center">
  <img src="images/dependencies.png" alt="dependencies" style="width: 400px;" align="right"/>
</p>

### Solution

- use [`make`](http://www.gnu.org/software/make/)

## make: targets

### Syntax:

*target: dependencies*  
*[tab] system command*

### Example:

```{r eval=FALSE, highlight=FALSE}
01_downloaded_data.csv: 01_download.R
	$(R_CMD) 01_download.R`
```

## make: macros

### Syntax:

*VAR = value*

### Example:

```{r eval=FALSE, highlight=FALSE}
R_CMD = R CMD BATCH  --no-save --no-restore --slave --no-timing
```

## make: Example

```{r eval=FALSE, highlight=FALSE}
# Macros

R_CMD = R CMD BATCH  --no-save --no-restore --slave --no-timing

# Targets

all: 01_downloaded_data.csv

01_downloaded_data.csv: 01_download.R makefile
	$(R_CMD) 01_download.R
```

<p align="center">
  <img src="images/dependencies_small.png" alt="dependencies" style="width: 400px;" align="right"/>
</p>

## make: Example

```{r eval=FALSE, highlight=FALSE}
# Macros

R_CMD = R CMD BATCH  --no-save --no-restore --slave --no-timing

# Targets

all: 03_model_output.Rds

01_downloaded_data.csv: 01_download.R makefile
	$(R_CMD) 01_download.R

02_munged_data.Rds: 02_munge.R 01_downloaded_data.csv outliers_to_remove.txt
	$(R_CMD) 02_munge.R

03_model_output.Rds: 03_model.R 02_munged_data.Rds model_config.txt
	$(R_CMD) 03_model.R
```

<p align="bottom">
  <img src="images/dependencies_medium.png" alt="dependencies" style="width: 300px;" align="right"/>
</p>

## make: Example

```{r eval=FALSE, highlight=FALSE}
# Macros

R_CMD = R CMD BATCH  --no-save --no-restore --slave --no-timing
R_SCRIPT = R --no-save --no-restore --no-init-file --no-site-file
SET_R_LIBS = .libPaths(c('~/Documents/R/win-library/3.2', \
                         'C:/Program Files/R/R-3.2.2/library'));
# Targets

all: 04_report_doc.docx

01_downloaded_data.csv: 01_download.R makefile
	$(R_CMD) 01_download.R

02_munged_data.Rds: 02_munge.R 01_downloaded_data.csv outliers_to_remove.txt
	$(R_CMD) 02_munge.R

03_model_output.Rds: 03_model.R 02_munged_data.Rds model_config.txt
	$(R_CMD) 03_model.R

04_report_doc.docx: 04_report.Rmd 03_model_output.Rds
	${R_SCRIPT} -e "${SET_R_LIBS} \
                  knitr::knit(inp='04_report.Rmd', out='04_report.md')"
	pandoc 04_report.md --to docx --output 04_report_doc.docx

clean:
	rm -f *.Rout
	rm -f 04_report.md
```

## Efficient, transparent, reproducible analyses are:

<img src="images/data_river_eddy.png" alt="data_river_eddy" style="width: 350px;" align="right"/>

### Readable
- readable code
- traceable data flow

### Self-contained
- complete from data to reports
- dependencies are embedded

<p align="top">
  <img src="images/dependencies.png" alt="dependencies" style="width: 300px;" align="right"/>
</p>

### Incorruptible
- judicious redundancy
- code versioning
- automated data flow



